{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - Weather Prediction\n",
        "\n",
        "\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_weather_prediction_on_vertex.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"\u003e\u003cbr\u003e Run in Colab Enterprise\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_weather_prediction_on_vertex.ipynb\"\u003e\n",
        "      \u003cimg alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"\u003e\u003cbr\u003e View on GitHub\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying [GraphCast](https://www.science.org/doi/10.1126/science.adi2336) and [GenCast](https://arxiv.org/abs/2312.15796) models on TPU using Vertex Model Garden science dockers.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Deploy deploying [GraphCast](https://www.science.org/doi/10.1126/science.adi2336) and [GenCast](https://arxiv.org/abs/2312.15796) on TPU\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264c07757582"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "### Request For TPU Quota\n",
        "\n",
        "By default, the quota for TPU training [Custom model training TPU v5e cores per region](https://console.cloud.google.com/iam-admin/quotas?location=us-central1\u0026metric=aiplatform.googleapis.com%2Fcustom_model_training_tpu_v5e) is 0. TPU quota is only available in `us-west1`, `us-west4`, `us-central1`. You can request for higher TPU quota following the instructions at [\"Request a higher quota\"](https://cloud.google.com/docs/quota/view-manage#requesting_higher_quota). It is suggested to request at least 4 v5e to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2707b02ef5df",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Setup Google Cloud project\n",
        "\n",
        "\n",
        "# @markdown 1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "# @markdown 2. **[Optional]** [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs. Set the BUCKET_URI for the experiment environment. The specified Cloud Storage bucket (`BUCKET_URI`) should be located in the same region as where the notebook was launched. Note that a multi-region bucket (eg. \"us\") is not considered a match for a single region covered by the multi-region range (eg. \"us-central1\"). If not set, a unique GCS bucket will be created instead.\n",
        "\n",
        "BUCKET_URI = \"gs://\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown 3. **[Optional]** TPU is only available in `us-west1`, `us-west4`, `us-central1`.\n",
        "\n",
        "# REGION = \"\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param [\"us-central1\", \"us-west1\", \"us-west4\"]\n",
        "\n",
        "# Import the necessary packages\n",
        "\n",
        "# Upgrade Vertex AI SDK.\n",
        "! pip3 install --upgrade --quiet 'google-cloud-aiplatform\u003e=1.64.0'\n",
        "! git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples.git\n",
        "! pip3 uninstall --quiet -y xarray\n",
        "! pip3 install --quiet xarray[complete]\n",
        "\n",
        "import datetime\n",
        "import importlib\n",
        "import os\n",
        "import uuid\n",
        "from typing import Tuple\n",
        "import glob\n",
        "\n",
        "from google.cloud import aiplatform, storage\n",
        "\n",
        "common_util = importlib.import_module(\n",
        "    \"vertex-ai-samples.community-content.vertex_model_garden.model_oss.notebook_util.common_util\"\n",
        ")\n",
        "\n",
        "# Get the default cloud project id.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "if not REGION:\n",
        "    REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Vertex AI API and Compute Engine API, if not already.\n",
        "print(\"Enabling Vertex AI API and Compute Engine API.\")\n",
        "! gcloud services enable aiplatform.googleapis.com compute.googleapis.com\n",
        "\n",
        "# Cloud Storage bucket for storing the experiment artifacts.\n",
        "# A unique GCS bucket will be created for the purpose of this notebook. If you\n",
        "# prefer using your own GCS bucket, change the value yourself below.\n",
        "now = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "\n",
        "if BUCKET_URI is None or BUCKET_URI.strip() == \"\" or BUCKET_URI == \"gs://\":\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-tmp-{now}-{str(uuid.uuid4())[:4]}\"\n",
        "    BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "    ! gsutil mb -l {REGION} {BUCKET_URI}\n",
        "else:\n",
        "    assert BUCKET_URI.startswith(\"gs://\"), \"BUCKET_URI must start with `gs://`.\"\n",
        "    shell_output = ! gsutil ls -Lb {BUCKET_NAME} | grep \"Location constraint:\" | sed \"s/Location constraint://\"\n",
        "    bucket_region = shell_output[0].strip().lower()\n",
        "    if bucket_region != REGION:\n",
        "        raise ValueError(\n",
        "            \"Bucket region %s is different from notebook region %s\"\n",
        "            % (bucket_region, REGION)\n",
        "        )\n",
        "print(f\"Using this GCS Bucket: {BUCKET_URI}\")\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "\n",
        "# Initialize Vertex AI API.\n",
        "print(\"Initializing Vertex AI API.\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Gets the default SERVICE_ACCOUNT.\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)\n",
        "\n",
        "\n",
        "# Provision permissions to the SERVICE_ACCOUNT with the GCS bucket\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.admin $BUCKET_NAME\n",
        "! gcloud config set project $PROJECT_ID\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/storage.admin\"\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/aiplatform.user\"\n",
        "\n",
        "\n",
        "# Utility functions for vertex jobs.\n",
        "def get_job_name_with_datetime(prefix: str) -\u003e str:\n",
        "    \"\"\"Gets the job name with date time when triggering training or deployment\n",
        "    jobs in Vertex AI.\n",
        "    \"\"\"\n",
        "    return prefix + datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "def get_bucket_and_blob_name(filepath):\n",
        "    # The gcs path is of the form gs:///\n",
        "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
        "    return tuple(gs_suffix.split(\"/\", 1))\n",
        "\n",
        "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
        "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
        "        if not os.path.isfile(local_file):\n",
        "            continue\n",
        "        filename = local_file[1 + len(local_dir_path) :]\n",
        "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
        "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(local_file)\n",
        "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))\n",
        "\n",
        "\n",
        "# Utility functions for prediction visualization.\n",
        "import matplotlib\n",
        "import xarray\n",
        "from typing import Optional\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import math\n",
        "from IPython.display import HTML\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "print(xarray.backends.list_engines())\n",
        "\n",
        "def select(\n",
        "    data: xarray.Dataset,\n",
        "    variable: str,\n",
        "    level: Optional[int] = None,\n",
        "    max_steps: Optional[int] = None\n",
        "    ) -\u003e xarray.Dataset:\n",
        "  data = data[variable]\n",
        "  if \"batch\" in data.dims:\n",
        "    data = data.isel(batch=0)\n",
        "  if max_steps is not None and \"time\" in data.sizes and max_steps \u003c data.sizes[\"time\"]:\n",
        "    data = data.isel(time=range(0, max_steps))\n",
        "  if level is not None and \"level\" in data.coords:\n",
        "    data = data.sel(level=level)\n",
        "  return data\n",
        "\n",
        "def scale(\n",
        "    data: xarray.Dataset,\n",
        "    center: Optional[float] = None,\n",
        "    robust: bool = False,\n",
        "    ) -\u003e tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "  vmin = np.nanpercentile(data, (2 if robust else 0))\n",
        "  vmax = np.nanpercentile(data, (98 if robust else 100))\n",
        "  if center is not None:\n",
        "    diff = max(vmax - center, center - vmin)\n",
        "    vmin = center - diff\n",
        "    vmax = center + diff\n",
        "  return (data, matplotlib.colors.Normalize(vmin, vmax),\n",
        "          (\"RdBu_r\" if center is not None else \"viridis\"))\n",
        "\n",
        "def plot_data(\n",
        "    data: dict[str, xarray.Dataset],\n",
        "    fig_title: str,\n",
        "    plot_size: float = 5,\n",
        "    robust: bool = False,\n",
        "    cols: int = 4\n",
        "    ) -\u003e tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "\n",
        "  first_data = next(iter(data.values()))[0]\n",
        "  max_steps = first_data.sizes.get(\"time\", 1)\n",
        "  assert all(max_steps == d.sizes.get(\"time\", 1) for d, _, _ in data.values())\n",
        "\n",
        "  cols = min(cols, len(data))\n",
        "  rows = math.ceil(len(data) / cols)\n",
        "  figure = plt.figure(figsize=(plot_size * 2 * cols,\n",
        "                               plot_size * rows))\n",
        "  figure.suptitle(fig_title, fontsize=16)\n",
        "  figure.subplots_adjust(wspace=0, hspace=0)\n",
        "  figure.tight_layout()\n",
        "\n",
        "  images = []\n",
        "  for i, (title, (plot_data, norm, cmap)) in enumerate(data.items()):\n",
        "    ax = figure.add_subplot(rows, cols, i+1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(title)\n",
        "    im = ax.imshow(\n",
        "        plot_data.isel(time=0, missing_dims=\"ignore\"), norm=norm,\n",
        "        origin=\"lower\", cmap=cmap)\n",
        "    plt.colorbar(\n",
        "        mappable=im,\n",
        "        ax=ax,\n",
        "        orientation=\"vertical\",\n",
        "        pad=0.02,\n",
        "        aspect=16,\n",
        "        shrink=0.75,\n",
        "        cmap=cmap,\n",
        "        extend=(\"both\" if robust else \"neither\"))\n",
        "    images.append(im)\n",
        "\n",
        "  def update(frame):\n",
        "    if \"time\" in first_data.dims:\n",
        "      td = datetime.timedelta(microseconds=first_data[\"time\"][frame].item() / 1000)\n",
        "      figure.suptitle(f\"{fig_title}, {td}\", fontsize=16)\n",
        "    else:\n",
        "      figure.suptitle(fig_title, fontsize=16)\n",
        "    for im, (plot_data, norm, cmap) in zip(images, data.values()):\n",
        "      im.set_data(plot_data.isel(time=frame, missing_dims=\"ignore\"))\n",
        "\n",
        "  ani = animation.FuncAnimation(\n",
        "      fig=figure, func=update, frames=max_steps, interval=250)\n",
        "  plt.close(figure.number)\n",
        "  return HTML(ani.to_jshtml())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction With Gencast And Graphcast Models"
      ],
      "metadata": {
        "id": "pzLRT5H6rmd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Config Models\n",
        "SCIENCE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/science-serve.tpu.0-1.debian12.py310:20250312_0715_RC00\"\n",
        "data_storage_dir = \"gs://vertex-model-garden-restricted-us/gdm-science\"\n",
        "\n",
        "example_type = \"gencast_small\" # @param [\"gencast_small\", \"graphcast_small\", \"graphcast_operational\"]\n",
        "accelerator_type = \"TPU_V5e\"\n",
        "# Note: 1 TPU V5 chip has only one core.\n",
        "\n",
        "print(\"Set basic configurations.\")\n",
        "if example_type == \"gencast_small\":\n",
        "  task_type = \"gencast\"\n",
        "  input_file_name = \"source-era5_date-2019-03-29_res-1.0_levels-13_steps-04.nc\"\n",
        "  model_name = \"GenCast 1p0deg Mini \u003c2019.npz\"\n",
        "  machine_type = \"ct5lp-hightpu-4t\"\n",
        "  tpu_topology = \"2x2\"\n",
        "  accelerator_count = 4\n",
        "elif example_type == \"graphcast_small\":\n",
        "  task_type = \"graphcast\"\n",
        "  input_file_name = \"source-era5_date-2022-01-01_res-1.0_levels-37_steps-12.nc\"\n",
        "  model_name = \"GraphCast_small - ERA5 1979-2015 - resolution 1.0 - pressure levels 13 - mesh 2to5 - precipitation input and output.npz\"\n",
        "  machine_type = \"ct5lp-hightpu-1t\"\n",
        "  tpu_topology = \"1x1\"\n",
        "  accelerator_count = 1\n",
        "elif example_type == \"graphcast_operational\":\n",
        "  task_type = \"graphcast\"\n",
        "  input_file_name = \"source-era5_date-2022-01-01_res-0.25_levels-37_steps-12.nc\"\n",
        "  model_name = \"GraphCast_operational - ERA5-HRES 1979-2021 - resolution 0.25 - pressure levels 13 - mesh 2to6 - precipitation output only.npz\"\n",
        "  machine_type = \"ct5lp-hightpu-1t\"\n",
        "  tpu_topology = \"1x1\"\n",
        "  accelerator_count = 1\n",
        "else:\n",
        "  raise ValueError(\"Invalid example_type.\")\n",
        "\n",
        "\n",
        "print(\"Check if there are enough quota.\")\n",
        "common_util.check_quota(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    accelerator_type=accelerator_type,\n",
        "    accelerator_count=accelerator_count,\n",
        "    is_for_training=True,\n",
        ")\n",
        "\n",
        "output_dir = f\"{BUCKET_URI}/science\"\n",
        "input_jsonl_name = f\"{task_type}_input.jsonl\"\n",
        "output_jsonl_name = f\"{task_type}_output.jsonl\"\n",
        "\n",
        "instances = [\n",
        "    {\n",
        "        \"input_file\": f\"{data_storage_dir}/{task_type}/dataset/{input_file_name}\",\n",
        "        \"output_dir\": output_dir\n",
        "    }\n",
        "]\n",
        "print(f\"The prediction instances: {instances}\")\n",
        "\n",
        "# Convert and write JSON object to file.\n",
        "os.makedirs(\"bath_prediction_input\", exist_ok=True)\n",
        "\n",
        "with open(f\"bath_prediction_input/{input_jsonl_name}\", \"w\") as outfile:\n",
        "    for item in instances:\n",
        "        json_str = json.dumps(item)\n",
        "        outfile.write(json_str)\n",
        "        outfile.write(\"\\n\")\n",
        "\n",
        "upload_local_dir_to_gcs(\n",
        "    \"bath_prediction_input\", output_dir\n",
        ")\n",
        "\n",
        "JOB_NAME = get_job_name_with_datetime(prefix=f\"jax_{task_type}\")\n",
        "\n",
        "input_jsonl = f\"{output_dir}/{input_jsonl_name}\"\n",
        "output_jsonl = f\"{output_dir}/{output_jsonl_name}\"\n",
        "\n",
        "docker_args_list = [\n",
        "    \"python3\",\n",
        "    \"./gdm_science/batch_prediction.py\",\n",
        "    f\"--task_type={task_type}\",\n",
        "    f\"--input_model_ckpt_file_path={data_storage_dir}/{task_type}/params/{model_name}\",\n",
        "    f\"--input_model_stats_dir={data_storage_dir}/{task_type}/stats\",\n",
        "    f\"--input_jsonl={input_jsonl}\",\n",
        "    f\"--output_jsonl={output_jsonl}\"\n",
        "]\n",
        "\n",
        "print(f\"The input json file will be {input_jsonl}.\")\n",
        "print(f\"The output json file will be {output_jsonl}.\")\n",
        "print(f\"The docker args list is {docker_args_list}.\")\n",
        "print(f\"The bucket uri is {BUCKET_URI}.\")\n",
        "print(f\"machine_type is {machine_type}.\")\n",
        "print(f\"tpu_topology is {tpu_topology}.\")\n",
        "print(f\"JOB_NAME is {JOB_NAME}.\")"
      ],
      "metadata": {
        "id": "Hf_7MhTIMSJp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Custom Jobs\n",
        "\n",
        "# Click on the generated link in the output under \"View backing custom job:\" to see your run in the Cloud Console.\n",
        "labels = {\n",
        "    \"mg-source\": \"notebook\",\n",
        "    \"mg-notebook-name\": \"model_garden_weather_prediction_on_vertex.ipynb\".split(\".\")[0],\n",
        "    \"mg-tune\": f\"publishers-google-models-{task_type}\".lower(),\n",
        "    \"versioned-mg-tune\": f\"publishers-google-models-{example_type}\".lower(),\n",
        "}\n",
        "\n",
        "job = aiplatform.CustomContainerTrainingJob(\n",
        "    display_name=JOB_NAME,\n",
        "    container_uri=SCIENCE_DOCKER_URI,\n",
        "    labels=labels,\n",
        ")\n",
        "\n",
        "model = job.run(\n",
        "    args=docker_args_list,\n",
        "    base_output_dir=f\"{BUCKET_URI}\",\n",
        "    replica_count=1,\n",
        "    machine_type=machine_type,\n",
        "    tpu_topology=tpu_topology,\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")"
      ],
      "metadata": {
        "id": "LSejOqyVUvdF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "M6p9GRWOgypH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Visualize the predicted results.\n",
        "\n",
        "prediction_data_path = os.path.join(output_dir, input_file_name.split(\".\")[0] + \"_predictions.zarr\") # @param\n",
        "# @markdown  (Optional) The sample to visualize if there are multiple samples.\n",
        "sample = 1 # @param\n",
        "\n",
        "print(prediction_data_path)\n",
        "predictions = xarray.open_zarr(prediction_data_path)\n",
        "\n",
        "plot_size = 7\n",
        "variable = \"2m_temperature\"\n",
        "level = None\n",
        "steps = predictions.dims[\"time\"]\n",
        "\n",
        "if \"sample\" in predictions:\n",
        "  # Visualize one sample if there are many.\n",
        "  visualized_data = predictions.isel(sample=sample)\n",
        "else:\n",
        "  visualized_data = predictions\n",
        "\n",
        "data = {\n",
        "    \" \": scale(select(visualized_data, variable, level, steps), robust=True),\n",
        "}\n",
        "\n",
        "fig_title = variable\n",
        "if \"level\" in predictions[variable].coords:\n",
        "  fig_title += f\" at {level} hPa\"\n",
        "\n",
        "plot_data(data, fig_title, plot_size, robust=True)"
      ],
      "metadata": {
        "id": "zP3b2vGDgvMN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af21a3cff1e0"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "911406c1561e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Delete the temporal buckets.\n",
        "\n",
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_URI\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_weather_prediction_on_vertex.ipynb",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
